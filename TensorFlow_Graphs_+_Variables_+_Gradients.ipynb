{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow - Graphs + Variables + Gradients.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNx2tlBdtNcEOzPjArL2AOG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoloceneda/Python-edu/blob/master/TensorFlow_Graphs_%2B_Variables_%2B_Gradients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyDf6fDaOh-o",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow - Computation Graph and Gradients\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjeDtabOOprs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jXJ2uehOrkF",
        "colab_type": "text"
      },
      "source": [
        "## Creating a computation graph\n",
        "TensorFlow relies on building computation graphs to perform computations and derive the relationship between tensors, from the input all the way to the output. A computation graph is a network of nodes, where each node represents a tensor or an operation, which applies a function to its input tensor(s) and returns zero or more output tensors. TensorFlow uses this computation graph to compute gradients.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR-fHHHMSZEC",
        "colab_type": "text"
      },
      "source": [
        "### TensorFlow v1.x\n",
        "TensorFlow v1.x's low-level API uses **static computation graphs**, which must be explicitly defined, although this is not trivial for large and complex models. The steps for building, compiling and evaluating a graph are:\n",
        "\n",
        "1. Instantiate an empty graph using `tf.Graph()`\n",
        "2. Add nodes to the computation graph using `g.as_default()`\n",
        "3. Evaluate the graph: \\\n",
        "     3.1 Start a new session using `tf.compat.v1.Session()` \\\n",
        "     3.2 Initialize the variables using `tf.compat.v1.global_variables_initializer()` \\\n",
        "     3.3 Execute the operations using `sess.run()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4CWkVhlXAaj",
        "colab_type": "code",
        "outputId": "4f9724e4-ce1b-4818-a03a-34bb2ebeaf8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Example with only constants\n",
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default():\n",
        "  a = tf.constant(1, name='a')\n",
        "  b = tf.constant(2, name='b')\n",
        "  c = tf.constant(3, name='c')\n",
        "  z = 2 * (a - b) + c\n",
        "\n",
        "with tf.compat.v1.Session(graph=g) as sess:\n",
        "  print('z =', sess.run(z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO4DlniPuUuW",
        "colab_type": "code",
        "outputId": "a37e8160-e039-4e9b-8137-9e4db2b72c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Example with only placeholders\n",
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default():\n",
        "  a = tf.compat.v1.placeholder(shape=None, dtype=tf.int32, name='tf_a')\n",
        "  b = tf.compat.v1.placeholder(shape=None, dtype=tf.int32, name='tf_b')\n",
        "  c = tf.compat.v1.placeholder(shape=None, dtype=tf.int32, name='tf_c')\n",
        "  z = 2 * (a - b) + c\n",
        "\n",
        "with tf.compat.v1.Session(graph=g) as sess:\n",
        "  print('z =', sess.run(z, feed_dict = {a: 1, b: 2, c: 3}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IwYcPnW1-Fk",
        "colab_type": "code",
        "outputId": "9cee7499-80a1-4b1b-f597-453ef3e6e5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Example with placeholders and variables\n",
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default():\n",
        "  x = tf.compat.v1.placeholder(shape=None, dtype=tf.float32, name='x')\n",
        "  w = tf.Variable(2.0, name='weight')\n",
        "  b = tf.Variable(0.7, name='bias')\n",
        "  z = w * x + b\n",
        "\n",
        "  init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "with tf.compat.v1.Session(graph=g) as sess:\n",
        "  sess.run(init)\n",
        "  for t in [1.0, 0.6, -1.8]:\n",
        "    print('x = {:>5.2f} --> z = {:>5.2f}'.format(t, sess.run(z, feed_dict={x: t})))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "x =  1.00 --> z =  2.70\n",
            "x =  0.60 --> z =  1.90\n",
            "x = -1.80 --> z = -2.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqj7MKohozwy",
        "colab_type": "text"
      },
      "source": [
        "### TensorFlow v2\n",
        "TensorFlow v2 uses **dynamic computation graphs** (also called eager execution), which allow to evaluate operations on the fly, without the need to explicitly create a graph, constants and a session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Afhx37cp1HV",
        "colab_type": "code",
        "outputId": "b3db862c-0cf0-471b-c758-545b6a2d4029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.constant(1, name='a')\n",
        "b = tf.constant(2, name='b')\n",
        "c = tf.constant(3, name='c')\n",
        "z = 2 * (a - b) + c\n",
        "\n",
        "print('z =', z.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrsN6mV7zlZb",
        "colab_type": "text"
      },
      "source": [
        "To **load input data** into a model, we can directly feed data in the form of Python variables or NumPy arrays, without the need to create a graph, placeholders and a session. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewMrvNnxxOyW",
        "colab_type": "code",
        "outputId": "ef40885f-942f-49fd-eda3-6f06a7896a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def compute_z(a, b, c):\n",
        "  z = tf.add(tf.multiply(2, tf.subtract(a, b)), c)\n",
        "  return z\n",
        "\n",
        "z = compute_z(1, 2, 3)\n",
        "print('z =', z.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU5daJn99OJQ",
        "colab_type": "text"
      },
      "source": [
        "Since dynamic graphs are not as computationally efficient as static ones, TensorFlow v2 automatically compiles Python **code into a static graph** using a tool called AutoGraph. Moreover, we can compile a **function into a static graph** using the `@tf.function` decorator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWESrk9SCtTi",
        "colab_type": "code",
        "outputId": "294151dc-39cf-441b-b21f-d8d1deafe4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "@tf.function\n",
        "def compute_z(a, b, c):\n",
        "  z = tf.add(tf.multiply(2, tf.subtract(a, b)), c)\n",
        "  return z\n",
        "\n",
        "z = compute_z(1, 2, 3)\n",
        "print('z =', z.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BPGQr-aqAvE",
        "colab_type": "text"
      },
      "source": [
        "**Limit the ways to call** a function using `tf.TensorSpec`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3x4Z_B0NqXD",
        "colab_type": "code",
        "outputId": "8363e284-4496-4b65-a916-37d9011d9bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32), tf.TensorSpec(shape=[None], dtype=tf.int32), tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
        "def compute_z(a, b, c):\n",
        "  z = tf.add(tf.multiply(2, tf.subtract(a, b)), c)\n",
        "  return z\n",
        "\n",
        "# Calling the function using tensors with rank 1 or lists that can be converted to rank 1 tensors:\n",
        "tf.print('Rank 1 inputs:', compute_z([1], [2], [3]))\n",
        "tf.print('Rank 1 inputs:', compute_z([1, 2], [2, 4], [3, 6]))\n",
        "\n",
        "# Calling the function using tensors with ranks other than 1 will result in errors:\n",
        "# tf.print('Rank 0 inputs:', compute_z(1, 2, 3)) \n",
        "# tf.print('Rank 2 Inputs:', compute_z([[1], [2]], [2], [4]], [[3], [6]]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rank 1 inputs: [1]\n",
            "Rank 1 inputs: [1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhsXGDY3WJQ5",
        "colab_type": "text"
      },
      "source": [
        "## Variable objects for storing and updating model parameters\n",
        "A variable is a special tensor that allows to store and update the parameters of our model during training.\n",
        "\n",
        "**Create a variable** using `tf.Variable`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df71mcB9cdNJ",
        "colab_type": "code",
        "outputId": "d245d58f-a244-4a31-f8fe-add4a6f617f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "a = tf.Variable(initial_value=3, name='var_a')\n",
        "print(a)\n",
        "\n",
        "b = tf.Variable(initial_value=[1, 2, 3], name='var_b')\n",
        "print(b)\n",
        "\n",
        "c = tf.Variable(initial_value=[True, False], dtype=tf.bool)\n",
        "print(c)\n",
        "\n",
        "d = tf.Variable(initial_value=['abc'], dtype=tf.string)\n",
        "print(d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'var_a:0' shape=() dtype=int32, numpy=3>\n",
            "<tf.Variable 'var_b:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>\n",
            "<tf.Variable 'Variable:0' shape=(2,) dtype=bool, numpy=array([ True, False])>\n",
            "<tf.Variable 'Variable:0' shape=(1,) dtype=string, numpy=array([b'abc'], dtype=object)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6LWMvYo9wCv",
        "colab_type": "text"
      },
      "source": [
        "To use a **variable inside a decorated function**, define the variable outside of the decorated function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvd4Zgq29wcm",
        "colab_type": "code",
        "outputId": "ec5076c8-4da4-44d5-e992-36fda31c01fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "w = tf.Variable(tf.random.uniform((2, 3)))\n",
        "\n",
        "@tf.function\n",
        "def compute_z(x):\n",
        "  return tf.matmul(w, x)\n",
        "\n",
        "x = tf.constant([[1], [2], [3]], dtype=tf.float32)\n",
        "print(compute_z(x).numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.2747576]\n",
            " [2.3064604]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIh1i2DhveE1",
        "colab_type": "text"
      },
      "source": [
        "**Specify trainable** and non-trainable variables using `trainable`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ZkM6qPvudZ",
        "colab_type": "code",
        "outputId": "1e10f767-4640-4e52-c66b-c4503b57d35b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = tf.Variable(initial_value=3, trainable=False)\n",
        "print('a trainable:', a.trainable)\n",
        "\n",
        "b = tf.Variable(initial_value=3, trainable=True)\n",
        "print('b.trainable:', b.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a trainable: False\n",
            "b.trainable: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkxj7imaxClQ",
        "colab_type": "text"
      },
      "source": [
        "**Modify the values** of a variable using `assign()`, `assign_add()`, and other methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMWXkjIaxcUV",
        "colab_type": "code",
        "outputId": "81df729b-8dec-40c5-c8d4-62c6a9ceeeb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "a = tf.Variable(initial_value=1)\n",
        "print('a before:', a.numpy())\n",
        "a.assign(value=3, read_value=True)\n",
        "print('a after:', a.numpy())\n",
        "\n",
        "b = tf.Variable(initial_value=[1, 2, 3])\n",
        "print('b before:', b.numpy())\n",
        "b.assign_add(delta=[1, 1, 1], read_value=True)\n",
        "print('b after:', b.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a before: 1\n",
            "a after: 3\n",
            "b before: [1 2 3]\n",
            "b after: [2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daNDEbX2bWm",
        "colab_type": "text"
      },
      "source": [
        "Initialize a variable with **random values** using `tf.keras.initializers`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N73DEVf82rMn",
        "colab_type": "code",
        "outputId": "efd09593-d7cf-45f7-f077-146dbb5fac29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(seed=1)\n",
        "init = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "print(init(shape=(3, )).numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.7227959   1.0145682   0.25180823]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvZhH50RKfs0",
        "colab_type": "text"
      },
      "source": [
        "## Computing gradients via automatic differentiation\n",
        "Optimizing neural networks via algorithms such as stochastic gradient descent requires computing the gradients of the cost with respect to the weights. TensorFlow supports automatic differentiation, which represents a set of computational techniques for computing derivatives or gradients of arithmetic operations. During this process, gradients of nested functions (expressed as a series of operations) are obtained by accumulating the gradients through repeated applications of the chain rule. \n",
        "\n",
        "Compute the **gradient wrt a trainable variable** using `tf.GradientTape`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqS70NhcXdtz",
        "colab_type": "code",
        "outputId": "8ae5ab99-ef04-45df-db65-ff3f281f6d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = tf.Variable(1.0, trainable=True)\n",
        "b = tf.Variable(0.5, trainable=True)\n",
        "\n",
        "x = tf.constant([1.4])\n",
        "y = tf.constant([2.1])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = tf.add(tf.multiply(w, x), b)\n",
        "  loss = tf.reduce_sum(tf.square(tf.subtract(y, z)))\n",
        "\n",
        "dloss_dw = tape.gradient(loss, w)\n",
        "print('dL/dw =', dloss_dw.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dL/dw = -0.55999976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdo59fQ7z3Ss",
        "colab_type": "text"
      },
      "source": [
        "Compute the **gradient wrt a non-trainable variable** using `tf.GradientTape` and `tape.watch`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv8unfCt0i-o",
        "colab_type": "code",
        "outputId": "a0b6bcc3-cf11-4a27-9702-ac806230186f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = tf.Variable(1.0, trainable=True)\n",
        "b = tf.Variable(0.5, trainable=True)\n",
        "\n",
        "x = tf.constant([1.4])\n",
        "y = tf.constant([2.1])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  z = tf.add(tf.multiply(w, x), b)\n",
        "  loss = tf.reduce_sum(tf.square(tf.subtract(y, z)))\n",
        "\n",
        "dloss_dx = tape.gradient(loss, x)\n",
        "print('dL/dx =', dloss_dx.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dL/dx = [-0.39999986]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKDu9fk_HMx1",
        "colab_type": "text"
      },
      "source": [
        "When we monitor computations with `tf.GradientTape`, by default the tape keeps the resources only for a single gradient computation: after calling `tape.gradient` once, the tape is cleared. \n",
        "\n",
        "To compute **more than one gradient**, we need to make the tape persistent. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e70u2J7fHxjk",
        "colab_type": "code",
        "outputId": "8f3df8db-e62f-46b9-efb0-3119889b3f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "w = tf.Variable(1.0, trainable=True)\n",
        "b = tf.Variable(0.5, trainable=True)\n",
        "\n",
        "x = tf.constant([1.4])\n",
        "y = tf.constant([2.1])\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  z = tf.add(tf.multiply(w, x), b)\n",
        "  loss = tf.reduce_sum(tf.square(tf.subtract(y, z)))\n",
        "\n",
        "dloss_dw = tape.gradient(loss, w)\n",
        "print('dL/dw =', dloss_dw.numpy())\n",
        "\n",
        "dloss_db = tape.gradient(loss, b)\n",
        "print('dL/db =', dloss_db.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dL/dw = -0.55999976\n",
            "dL/db = -0.39999986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH8y4uxzJ3Ie",
        "colab_type": "text"
      },
      "source": [
        "Define an optimizer and apply the gradients to optimize the model parameters using `tf.keras.optimizers`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dw_VJWSKBzN",
        "colab_type": "code",
        "outputId": "5ab06f58-722a-42a3-bc20-8fe275614df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "w = tf.Variable(1.0, trainable=True)\n",
        "b = tf.Variable(0.5, trainable=True)\n",
        "\n",
        "x = tf.constant([1.4])\n",
        "y = tf.constant([2.1])\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  z = tf.add(tf.multiply(w, x), b)\n",
        "  loss = tf.reduce_sum(tf.square(tf.subtract(y, z)))\n",
        "\n",
        "dloss_dw = tape.gradient(loss, w)\n",
        "dloss_db = tape.gradient(loss, b)\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD()\n",
        "optimizer.apply_gradients(zip([dloss_dw, dloss_db], [w, b]))\n",
        "print('Updated w:', w.numpy())\n",
        "print('Updated b:', b.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated w: 1.0056\n",
            "Updated b: 0.504\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}