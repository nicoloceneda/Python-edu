{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow - Dataset API.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMB8zoFY3HG5ZZupJSzK6gk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoloceneda/Python-edu/blob/master/TensorFlow_Dataset_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulcwvc0MgOLb",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow - Dataset API\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTd0ii4lfqoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2JTnYLvgaPa",
        "colab_type": "text"
      },
      "source": [
        "## Creating a TensorFlow Dataset from existing tensors\n",
        "Create a dataset from a **list**, a **Numpy array** or a **tensor** using `tf.data.Dataset.from_tensor_slices`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGsqxXuJraSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d9ef9f89-5f72-44d5-940a-a8f69b2309fc"
      },
      "source": [
        "a = [1, 2, 3]\n",
        "dataset_a = tf.data.Dataset.from_tensor_slices(a)\n",
        "print(dataset_a)\n",
        "\n",
        "b = np.array([4, 5, 6])\n",
        "dataset_b = tf.data.Dataset.from_tensor_slices(b)\n",
        "print(dataset_b)\n",
        "\n",
        "c = tf.constant([7, 8, 9])\n",
        "dataset_c = tf.data.Dataset.from_tensor_slices(c)\n",
        "print(dataset_c)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: (), types: tf.int32>\n",
            "<TensorSliceDataset shapes: (), types: tf.int64>\n",
            "<TensorSliceDataset shapes: (), types: tf.int32>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRVOcqYCsmke",
        "colab_type": "text"
      },
      "source": [
        "Iterate **entry by entry** through a dataset using `for ... in`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEPhU0nHsyrn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "26253448-5028-47a5-a0f1-6e21d1262156"
      },
      "source": [
        "a = [1, 2, 3]\n",
        "dataset_a = tf.data.Dataset.from_tensor_slices(a)\n",
        "\n",
        "for pos, item in enumerate(dataset_a):\n",
        "  print('item {}'.format(pos), item)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item 0 tf.Tensor(1, shape=(), dtype=int32)\n",
            "item 1 tf.Tensor(2, shape=(), dtype=int32)\n",
            "item 2 tf.Tensor(3, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j57XgLH4tVd8",
        "colab_type": "text"
      },
      "source": [
        "Create **batches** from a dataset using `batch`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDxGvMnWtmD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "49cf4aec-bc01-48e9-dd25-840bd06d0cff"
      },
      "source": [
        "a = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "dataset_a = tf.data.Dataset.from_tensor_slices(a)\n",
        "\n",
        "dataset_batch = dataset_a.batch(batch_size=3)\n",
        "\n",
        "for pos, batch in enumerate(dataset_batch):\n",
        "  print('batch {}:'.format(pos), batch)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch 0: tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
            "batch 1: tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
            "batch 2: tf.Tensor([7 8 9], shape=(3,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiwWnifFuscv",
        "colab_type": "text"
      },
      "source": [
        "## Combining two tensors into a joint dataset\n",
        "Create a **joint dataset** (to create a one-to-one correspondence between the elements of two tensors) using `tf.data.Dataset.zip` or `tf.data.Dataset.from_tensor_slices`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7nb5-FgvQQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d6ff4fa0-1e90-478c-9f59-bb1275c61a01"
      },
      "source": [
        "# First create two separate datasets, then join them (zip)\n",
        "tensor_a = tf.random.uniform(shape=(4, 3), minval=0, maxval=1, dtype=tf.float64)\n",
        "dataset_a = tf.data.Dataset.from_tensor_slices(tensor_a)\n",
        "\n",
        "tensor_b = tf.random.uniform(shape=(4, ), minval=0, maxval=4, dtype=tf.int64)\n",
        "dataset_b = tf.data.Dataset.from_tensor_slices(tensor_b)\n",
        "\n",
        "dataset_c = tf.data.Dataset.zip((dataset_a, dataset_b))\n",
        "\n",
        "for item in dataset_c:\n",
        "  print('x:', item[0].numpy(), 'y:', item[1].numpy())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: [0.32045744 0.33842543 0.91074693] y: 1\n",
            "x: [0.89966699 0.30803455 0.49515623] y: 2\n",
            "x: [0.30847655 0.66568763 0.14313214] y: 2\n",
            "x: [0.9777679  0.60444822 0.65572032] y: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVp3-Nh5zUzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3c97d0a0-ceca-4112-f63d-f589994d4931"
      },
      "source": [
        "# Directly create a joint dataset (from_tensor_slices)\n",
        "tensor_a = tf.random.uniform(shape=(4, 3), minval=0, maxval=1, dtype=tf.float64)\n",
        "tensor_b = tf.random.uniform(shape=(4, ), minval=0, maxval=4, dtype=tf.int64)\n",
        "\n",
        "dataset_c = tf.data.Dataset.from_tensor_slices((tensor_a, tensor_b))\n",
        "\n",
        "for item in dataset_c:\n",
        "  print('x:', item[0].numpy(), 'y:', item[1].numpy())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: [0.38623001 0.77751202 0.44822608] y: 2\n",
            "x: [0.06361701 0.0336372  0.23347828] y: 2\n",
            "x: [0.82468352 0.07897202 0.57829134] y: 0\n",
            "x: [0.32838318 0.55132781 0.26043303] y: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCjtnn7d3xWU",
        "colab_type": "text"
      },
      "source": [
        "Apply **feature scaling** to scale the values to the range [-1, +1] using `map`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D1uOTiu3-YL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}