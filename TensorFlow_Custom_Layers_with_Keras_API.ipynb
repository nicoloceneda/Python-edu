{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow - Custom Layers with Keras API.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIq4njIEHzUP2mKcoJRHl+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoloceneda/Python-edu/blob/master/TensorFlow_Custom_Layers_with_Keras_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nymC9IcIKlEs",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow - Custom Layer with Keras API \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiPmKn1GKTMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNEv7jz0NALh",
        "colab_type": "text"
      },
      "source": [
        "## Adding weights\n",
        "A Layer is the main data structure that encapsulates a state (the weights w and b) and a transformation from inputs to outputs (the forward pass defined in call). \n",
        "\n",
        "**Add trainable weights** to a layer `manually` or using `add_weight`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_T1n-nzPBND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1660d05e-b626-4c8e-f65d-67d7a94b7191"
      },
      "source": [
        "# Add trainable weights manually\n",
        "class Linear(layers.Layer):\n",
        "\n",
        "  def __init__(self, units=32, input_dim=32):\n",
        "    super(Linear, self).__init__()\n",
        "    w_init = tf.random_normal_initializer()\n",
        "    self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units), dtype='float32'), trainable=True)\n",
        "    b_init = tf.zeros_initializer()\n",
        "    self.b = tf.Variable(initial_value=b_init(shape=(units, ), dtype='float32'), trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.linalg.matmul(inputs, self.w) + self.b\n",
        "\n",
        "x = tf.ones((2, 2))\n",
        "\n",
        "linear_layer = Linear(units=4, input_dim=2)\n",
        "y = linear_layer(inputs=x)\n",
        "print(y.numpy())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.01778614 0.00810714 0.11528654 0.02348447]\n",
            " [0.01778614 0.00810714 0.11528654 0.02348447]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkDw24ne7CXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f0fc84aa-c53d-43a4-a5a4-7ff9b9a6416b"
      },
      "source": [
        "# Add trainable weights using add_weight\n",
        "class Linear(layers.Layer):\n",
        "\n",
        "  def __init__(self, units=32, input_dim=32):\n",
        "    super(Linear, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal', trainable=True)\n",
        "    self.b = self.add_weight(shape=(units, ), initializer='zeros', trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.linalg.matmul(inputs, self.w) + self.b\n",
        "\n",
        "  x = tf.ones((2, 2))\n",
        "\n",
        "  linear_layer = Linear(units=4, input_dim=2)\n",
        "  y = linear_layer(inputs=x)\n",
        "  print(y.numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.02587924  0.14166737 -0.03810942 -0.06730217]\n",
            " [ 0.02587924  0.14166737 -0.03810942 -0.06730217]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTiPyiAB_Dbv",
        "colab_type": "text"
      },
      "source": [
        "**Add non-trainable weights** (which are meant not to be taken into account during the backpropagation process of training) to a Layer `manually`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZCjV9oC_bVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a9a4a3ee-4e5a-46a0-928c-a1e001b7bce2"
      },
      "source": [
        "class ComputeSum(layers.Layer):\n",
        "\n",
        "  def __init__(self, input_dim=32):\n",
        "    super(ComputeSum, self).__init__()\n",
        "    self.total = tf.Variable(initial_value=tf.zeros((input_dim, )), trainable=False)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n",
        "    return self.total\n",
        "\n",
        "x = tf.ones((2, 2))\n",
        "\n",
        "my_sum = ComputeSum(input_dim=2)\n",
        "y = my_sum(inputs=x)\n",
        "print(y.numpy())\n",
        "y = my_sum(inputs=x)\n",
        "print(y.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2.]\n",
            "[4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXdSMcBeE-Oz",
        "colab_type": "text"
      },
      "source": [
        "**Defer weight creation** until the shape of the inputs is known using `add_weight` inside `build(input_shape)`. Doing so, the weights are created dynamically the first time the layer is called. This is the best practice as in many cases the size of the inputs is not known in advance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft5lWBDDOZh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "29283922-4aa7-4a99-b62c-3da809eb1dd8"
      },
      "source": [
        "class Linear(layers.Layer):\n",
        "\n",
        "  def __init__(self, units=32):\n",
        "    super(Linear, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_dim=32):\n",
        "    self.w = self.add_weight(shape=(input_dim[-1], self.units), initializer='random_normal', trainable=True)\n",
        "    self.b = self.add_weight(shape=(self.units, ), initializer='zeros', trainable=True)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "x = tf.ones((2, 2))\n",
        "\n",
        "linear_layer = Linear(units=4)\n",
        "y = linear_layer(inputs=x)\n",
        "print(y.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3) 3\n",
            "[[ 0.10048345  0.10018738 -0.03829457 -0.0474291 ]\n",
            " [ 0.10048345  0.10018738 -0.03829457 -0.0474291 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J98Avj9d9jH",
        "colab_type": "text"
      },
      "source": [
        "## Recursively defined layers and losses\n",
        "Define **layers recursively** (a layer instance is assigned as attribute of another layer) by defining them in the `__init__` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8M8aDosg7mE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "11be9b22-cb2c-4b53-bbbd-24432644bdb9"
      },
      "source": [
        "class Linear(layers.Layer):\n",
        "\n",
        "  def __init__(self, units=32):\n",
        "    super(Linear, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer='random_normal', trainable=True)\n",
        "    self.b = self.add_weight(shape=(self.units, ), initializer='zeros', trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "class MLPBlock(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MLPBlock, self).__init__()\n",
        "    self.linear_1 = Linear(units=32)\n",
        "    self.linear_2 = Linear(units=32)\n",
        "    self.linear_3 = Linear(units=1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.linear_1(inputs)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.linear_2(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    return self.linear_3(x)\n",
        "\n",
        "x = tf.ones(shape=(3, 64))\n",
        "\n",
        "mlp = MLPBlock()\n",
        "y = mlp(inputs=x)\n",
        "print(y.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.01583333]\n",
            " [-0.01583333]\n",
            " [-0.01583333]]\n",
            "weights: 6\n",
            "trainable weights: 6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}